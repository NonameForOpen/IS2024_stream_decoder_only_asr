# Copyright (c) 2020 Mobvoi Inc. (authors: Binbin Zhang, Di Wu)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# Modified from ESPnet(https://github.com/espnet/espnet)

from collections import defaultdict
from typing import Dict, List, Optional, Tuple

import torch

from torch.nn.utils.rnn import pad_sequence
from torch.nn import CrossEntropyLoss

from wenet.transformer.ctc import CTC
from wenet.transformer.decoder import TransformerDecoder
from wenet.transformer.encoder import TransformerEncoder
from wenet.transformer.label_smoothing_loss import LabelSmoothingLoss
from wenet.utils.common import (IGNORE_ID, add_sos_eos, log_add,
                                remove_duplicates_and_blank, th_accuracy,
                                reverse_pad_list)
from wenet.utils.mask import (make_pad_mask, mask_finished_preds,
                              mask_finished_scores, subsequent_mask)

from wenet.baichuan.modeling_baichuan import BaiChuanForCausalLM
from wenet.baichuan.configuration_baichuan import BaiChuanConfig


import logging

class ASRModel(torch.nn.Module):
    """CTC-attention hybrid Encoder-Decoder model"""
    def __init__(
        self,
        vocab_size: int,
        llm: Optional[PreTrainedModel],
        llm_conf: Optional[PretrainedConfig],
        ignore_id: int = IGNORE_ID,
        centor_weight: float = 0.0,
        sdc_weight: float = 0.0,
        lsm_weight: float = 0.0,
        length_normalized_loss: bool = False,
    ):

        super().__init__()
        # note that eos is the same as sos (equivalent ID)
        self.vocab_size = vocab_size
        self.ignore_id = ignore_id
        self.centor_weight = centor_weight
        self.sdc_weight = sdc_weight

        self.llm = llm
        self.llm_conf = llm_conf
        self.llm.set_input_embeddings(torch.nn.Embedding(vocab_size, llm_conf.hidden_size, self.ignore_id))
        self.llm.set_output_embeddings(torch.nn.Linear(self.llm_conf.hidden_size, vocab_size))
        self.llm.config.vocab_size = vocab_size

    def forward(
        self,
        speech: torch.Tensor,
        speech_lengths: torch.Tensor,
        text: torch.Tensor,
        text_lengths: torch.Tensor,
    ) -> Dict[str, Optional[torch.Tensor]]:
        """Frontend + Encoder + Decoder + Calc loss

        Args:
            speech: (Batch, Length, ...)
            speech_lengths: (Batch, )
            text: (Batch, Length)
            text_lengths: (Batch,)
        """
        assert text_lengths.dim() == 1, text_lengths.shape
        # Check that batch_size is unified
        assert (speech.shape[0] == speech_lengths.shape[0] == text.shape[0] ==
                text_lengths.shape[0]), (speech.shape, speech_lengths.shape,
                                         text.shape, text_lengths.shape)
        mask = ~make_pad_mask(text_lengths-1)
        #logging.info(speech)
        #logging.info(text)
        loss_llm: Optional[torch.Tensor] = None
        loss_llm, acc_llm = self._calc_att_loss(speech, mask, text)
        loss = loss_llm
        loss_log = {"loss": loss, "loss_att": loss_llm, "loss_acc": torch.tensor(acc_llm)}
        return loss_log

    def _calc_att_loss(
        self,
        llm_inp: torch.Tensor,
        llm_out_masks: torch.Tensor,
        labels: torch.Tensor,
    ) -> Tuple[torch.Tensor, float]:
        B, T = llm_inp.size()
        llm_out = self.llm(input_ids=llm_inp, labels=labels)
        loss = llm_out.loss.reshape(B, -1)
        #logging.info(loss.masked_fill(~llm_out_masks, 0.0))
        #logging.info(f'{llm_inp.size()} {llm_out_masks.size()} {labels.size()}')
        #logging.info(f'{loss.size()} {encoder_out.logits.size()}')
        #exit()
        loss = loss.masked_fill(~llm_out_masks, 0.0).sum(-1) / llm_out_masks.sum(-1)
        loss = loss.sum() / B
        #logging.info(f'{encoder_out.logits[..., :-1, :].size()} {labels[..., 1:].size()}')
        acc = th_accuracy(
            llm_out.logits[..., :-1, :].reshape(B * (T-1), -1),
            labels[..., 1:],
            ignore_label=self.ignore_id,
        )
        return loss, acc
